{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expedia Personalised Hotel Searches\n",
    "VU Data Mining Techniques 2024 | Assignment 2 | Group 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/training_set_VU_DM.csv'\n",
    "test_path = 'data/test_set_VU_DM.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "###### ToDo Jaime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitive_metrics = ['compX_rate', 'compX_inv', \"compX_rate_percent_diff\"]\n",
    "full_competitive_metrics = []\n",
    "for metric in competitive_metrics:\n",
    "    metric_list = []\n",
    "    for x in range(1,9):\n",
    "        metric_list.append(metric.replace(\"X\", str(x)))\n",
    "    full_competitive_metrics.append(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[full_competitive_metrics[2]].dropna(axis = 'index', how = 'all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too much nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[full_competitive_metrics[1]].dropna(axis = 'index', how = 'all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature not relevant enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_comp_rate'] = df[full_competitive_metrics[0]].iloc[:, :].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_rate_nan_index = df.index.difference(df[full_competitive_metrics[0]].dropna(axis = 'index', how = 'all').index)\n",
    "df.loc[comp_rate_nan_index, 'combined_comp_rate'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pd.unique(df['srch_id'])))\n",
    "print(df['click_bool'].sum())\n",
    "print(df['booking_bool'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average more clicks than searches. On average less bookings than searches. Makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vars_dist(df):\n",
    "    variables = [var for var in df if var not in ['srch_id','date_time']]  # ignoring these as they are only 1 value indicating occurence of a call/sms\n",
    "    fig, axes = plt.subplots(nrows=len(variables), ncols=1, figsize=(10, 6 * len(variables)))\n",
    "\n",
    "    for ax, var in zip(axes.flatten(), variables):\n",
    "        var_data = df[var]\n",
    "        mean = var_data.mean()\n",
    "        std = var_data.std()\n",
    "        # Adjust bins for better visualization based on data range and characteristics\n",
    "        bins = min(30, int(var_data.nunique()))  # Use a minimum of 30 bins or less if fewer unique values\n",
    "\n",
    "        ax.hist(var_data, bins=bins, alpha=0.75, color='blue', edgecolor='black', label=f'{var} Scores')\n",
    "        ax.set_title(f'Distribution of {var} values')\n",
    "        ax.set_xlabel(f'{var.capitalize()} Score')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(axis='y', alpha=0.75)\n",
    "        legend_label = f\"Mean: {mean:.2f}, Std: {std:.2f}\"\n",
    "        ax.legend([f\"{var.capitalize()} Scores\\n{legend_label}\"], loc='upper right', title='Statistics', frameon=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vars_dist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.drop(['srch_id','date_time'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "###### ToDo Ryan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype Conversion & Grouping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4958347 entries, 0 to 4958346\n",
      "Data columns (total 54 columns):\n",
      " #   Column                       Dtype         \n",
      "---  ------                       -----         \n",
      " 0   srch_id                      int64         \n",
      " 1   date_time                    datetime64[ns]\n",
      " 2   site_id                      category      \n",
      " 3   visitor_location_country_id  category      \n",
      " 4   visitor_hist_starrating      float64       \n",
      " 5   visitor_hist_adr_usd         float64       \n",
      " 6   prop_country_id              category      \n",
      " 7   prop_id                      int64         \n",
      " 8   prop_starrating              int64         \n",
      " 9   prop_review_score            float64       \n",
      " 10  prop_brand_bool              bool          \n",
      " 11  prop_location_score1         float64       \n",
      " 12  prop_location_score2         float64       \n",
      " 13  prop_log_historical_price    float64       \n",
      " 14  position                     int64         \n",
      " 15  price_usd                    float64       \n",
      " 16  promotion_flag               bool          \n",
      " 17  srch_destination_id          int64         \n",
      " 18  srch_length_of_stay          int64         \n",
      " 19  srch_booking_window          int64         \n",
      " 20  srch_adults_count            int64         \n",
      " 21  srch_children_count          int64         \n",
      " 22  srch_room_count              int64         \n",
      " 23  srch_saturday_night_bool     bool          \n",
      " 24  srch_query_affinity_score    float64       \n",
      " 25  orig_destination_distance    float64       \n",
      " 26  random_bool                  bool          \n",
      " 27  comp1_rate                   float64       \n",
      " 28  comp1_inv                    float64       \n",
      " 29  comp1_rate_percent_diff      float64       \n",
      " 30  comp2_rate                   float64       \n",
      " 31  comp2_inv                    float64       \n",
      " 32  comp2_rate_percent_diff      float64       \n",
      " 33  comp3_rate                   float64       \n",
      " 34  comp3_inv                    float64       \n",
      " 35  comp3_rate_percent_diff      float64       \n",
      " 36  comp4_rate                   float64       \n",
      " 37  comp4_inv                    float64       \n",
      " 38  comp4_rate_percent_diff      float64       \n",
      " 39  comp5_rate                   float64       \n",
      " 40  comp5_inv                    float64       \n",
      " 41  comp5_rate_percent_diff      float64       \n",
      " 42  comp6_rate                   float64       \n",
      " 43  comp6_inv                    float64       \n",
      " 44  comp6_rate_percent_diff      float64       \n",
      " 45  comp7_rate                   float64       \n",
      " 46  comp7_inv                    float64       \n",
      " 47  comp7_rate_percent_diff      float64       \n",
      " 48  comp8_rate                   float64       \n",
      " 49  comp8_inv                    float64       \n",
      " 50  comp8_rate_percent_diff      float64       \n",
      " 51  click_bool                   bool          \n",
      " 52  gross_bookings_usd           float64       \n",
      " 53  booking_bool                 bool          \n",
      "dtypes: bool(6), category(3), datetime64[ns](1), float64(34), int64(10)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "\n",
    "boolean_features = ['prop_brand_bool', 'promotion_flag', 'srch_saturday_night_bool', 'random_bool', 'click_bool', 'booking_bool']\n",
    "for col in boolean_features:\n",
    "    df[col] = df[col].astype('bool')\n",
    "    \n",
    "categorical_features = ['site_id', 'visitor_location_country_id', 'prop_country_id']  # 'srch_id', 'prop_id' and 'srch_destination_id' are not included because they are real identifiers rather than categorical features\n",
    "for col in categorical_features:\n",
    "    df[col] = df[col].astype('category')\n",
    "    \n",
    "numerical_features = [col for col in df.columns if col not in boolean_features + categorical_features + ['date_time', 'srch_id', 'prop_id', 'srch_destination_id']]\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values for Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values replaced with 0:\n",
      "visitor_hist_starrating - 4706481\n",
      "visitor_hist_adr_usd - 4705359\n",
      "prop_starrating - 0\n",
      "prop_review_score - 7364\n",
      "prop_location_score1 - 0\n",
      "prop_location_score2 - 1090348\n",
      "prop_log_historical_price - 0\n",
      "position - 0\n",
      "price_usd - 0\n",
      "srch_length_of_stay - 0\n",
      "srch_booking_window - 0\n",
      "srch_adults_count - 0\n",
      "srch_children_count - 0\n",
      "srch_room_count - 0\n",
      "srch_query_affinity_score - 4640941\n",
      "orig_destination_distance - 1607782\n",
      "comp1_rate - 4838417\n",
      "comp1_inv - 4828788\n",
      "comp1_rate_percent_diff - 4863908\n",
      "comp2_rate - 2933675\n",
      "comp2_inv - 2828078\n",
      "comp2_rate_percent_diff - 4402109\n",
      "comp3_rate - 3424059\n",
      "comp3_inv - 3307357\n",
      "comp3_rate_percent_diff - 4485550\n",
      "comp4_rate - 4650969\n",
      "comp4_inv - 4614684\n",
      "comp4_rate_percent_diff - 4827261\n",
      "comp5_rate - 2735974\n",
      "comp5_inv - 2598327\n",
      "comp5_rate_percent_diff - 4117248\n",
      "comp6_rate - 4718190\n",
      "comp6_inv - 4697371\n",
      "comp6_rate_percent_diff - 4862173\n",
      "comp7_rate - 4642999\n",
      "comp7_inv - 4601925\n",
      "comp7_rate_percent_diff - 4819832\n",
      "comp8_rate - 3041693\n",
      "comp8_inv - 2970844\n",
      "comp8_rate_percent_diff - 4343617\n",
      "gross_bookings_usd - 4819957\n"
     ]
    }
   ],
   "source": [
    "print('Missing values replaced with 0:')\n",
    "print('------------------------------')\n",
    "for feature in numerical_features:\n",
    "    print(f'{feature} - {df[feature].isna().sum()}')\n",
    "    df.fillna({feature: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero was chosen as the imputation value for the numerical features because it intuitively denotes a missing record. Furthermore, for the competitor data where we have either +1, 0, -1, assuming 0 in the case of missing data assumes no advantage for Expedia or a competitor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Features with Many Missing Values\n",
    "Not done anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a list of columns to drop where more than 50% of the data is missing\n",
    "# columns_to_drop = df.columns[df.isnull().mean() > 0.5].tolist()\n",
    "# pprint(f'Columns that are dropped due to excessive missing values: {columns_to_drop}')\n",
    "# df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising/Standardising Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation (scaling data between 0 and 1) or standardisation (shifting the distribution to have a mean of zero and a standard deviation of one) can be beneficial for algorithms that are sensitive to the scale of input data (like SVM or KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Example: Standardizing 'price_usd'\n",
    "scaler = StandardScaler()\n",
    "df['price_usd'] = scaler.fit_transform(df[['price_usd']])\n",
    "\n",
    "# Or for normalization\n",
    "# scaler = MinMaxScaler()\n",
    "# df['price_usd'] = scaler.fit_transform(df[['price_usd']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for 1-hot encoding a categorical feature\n",
    "df = pd.get_dummies(df, columns=['prop_country_id'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for this:\n",
    "1. Time Features: Break down the date_time column into year, month, day, weekday, and hour components. Time could affect booking patterns.\n",
    "2. Interaction Features: Create features that represent interactions between the customer’s historical preferences and property attributes, like the difference between the user’s average star rating and the property’s star rating.\n",
    "3. Textual and Categorical Embeddings: If there are textual descriptions available or high-cardinality categorical variables, consider using embeddings or hashing techniques to reduce their dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "df['year'] = df['date_time'].dt.year\n",
    "df['month'] = df['date_time'].dt.month\n",
    "df['day'] = df['date_time'].dt.day\n",
    "df['weekday'] = df['date_time'].dt.weekday\n",
    "df['hour'] = df['date_time'].dt.hour\n",
    "\n",
    "# Interaction feature: difference between user's average star rating and property's star rating\n",
    "df['starrating_diff'] = df['visitor_hist_starrating'] - df['prop_starrating']\n",
    "\n",
    "# Re-check the dataset\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
