{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id           date_time  site_id  visitor_location_country_id  \\\n",
       "0        1 2013-04-04 08:32:15       12                          187   \n",
       "1        1 2013-04-04 08:32:15       12                          187   \n",
       "2        1 2013-04-04 08:32:15       12                          187   \n",
       "3        1 2013-04-04 08:32:15       12                          187   \n",
       "4        1 2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      NaN                   NaN              219      893   \n",
       "1                      NaN                   NaN              219    10404   \n",
       "2                      NaN                   NaN              219    21315   \n",
       "3                      NaN                   NaN              219    27348   \n",
       "4                      NaN                   NaN              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score  ...  comp6_rate_percent_diff  \\\n",
       "0                3                3.5  ...                      NaN   \n",
       "1                4                4.0  ...                      NaN   \n",
       "2                3                4.5  ...                      NaN   \n",
       "3                2                4.0  ...                      NaN   \n",
       "4                4                3.5  ...                      NaN   \n",
       "\n",
       "   comp7_rate  comp7_inv  comp7_rate_percent_diff  comp8_rate  comp8_inv  \\\n",
       "0         NaN        NaN                      NaN         0.0        0.0   \n",
       "1         NaN        NaN                      NaN         0.0        0.0   \n",
       "2         NaN        NaN                      NaN         0.0        0.0   \n",
       "3         NaN        NaN                      NaN        -1.0        0.0   \n",
       "4         NaN        NaN                      NaN         0.0        0.0   \n",
       "\n",
       "   comp8_rate_percent_diff  click_bool  gross_bookings_usd  booking_bool  \n",
       "0                      NaN           0                 NaN             0  \n",
       "1                      NaN           0                 NaN             0  \n",
       "2                      NaN           0                 NaN             0  \n",
       "3                      5.0           0                 NaN             0  \n",
       "4                      NaN           0                 NaN             0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/training_set_VU_DM.csv', parse_dates=['date_time'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4958347\n"
     ]
    }
   ],
   "source": [
    "num_records = train_df.shape[0]\n",
    "print('Number of records:', num_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique searches: 199795\n"
     ]
    }
   ],
   "source": [
    "num_searches = train_df['srch_id'].nunique()\n",
    "print('Number of unique searches:', num_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with missing values: 31\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for column in train_df.columns:\n",
    "    if train_df[column].isnull().any():\n",
    "        count += 1\n",
    "print('Number of columns with missing values:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srch_id: 0.00% missing\n",
      "date_time: 0.00% missing\n",
      "site_id: 0.00% missing\n",
      "visitor_location_country_id: 0.00% missing\n",
      "visitor_hist_starrating: 94.92% missing\n",
      "visitor_hist_adr_usd: 94.90% missing\n",
      "prop_country_id: 0.00% missing\n",
      "prop_id: 0.00% missing\n",
      "prop_starrating: 0.00% missing\n",
      "prop_review_score: 0.15% missing\n",
      "prop_brand_bool: 0.00% missing\n",
      "prop_location_score1: 0.00% missing\n",
      "prop_location_score2: 21.99% missing\n",
      "prop_log_historical_price: 0.00% missing\n",
      "position: 0.00% missing\n",
      "price_usd: 0.00% missing\n",
      "promotion_flag: 0.00% missing\n",
      "srch_destination_id: 0.00% missing\n",
      "srch_length_of_stay: 0.00% missing\n",
      "srch_booking_window: 0.00% missing\n",
      "srch_adults_count: 0.00% missing\n",
      "srch_children_count: 0.00% missing\n",
      "srch_room_count: 0.00% missing\n",
      "srch_saturday_night_bool: 0.00% missing\n",
      "srch_query_affinity_score: 93.60% missing\n",
      "orig_destination_distance: 32.43% missing\n",
      "random_bool: 0.00% missing\n",
      "comp1_rate: 97.58% missing\n",
      "comp1_inv: 97.39% missing\n",
      "comp1_rate_percent_diff: 98.10% missing\n",
      "comp2_rate: 59.17% missing\n",
      "comp2_inv: 57.04% missing\n",
      "comp2_rate_percent_diff: 88.78% missing\n",
      "comp3_rate: 69.06% missing\n",
      "comp3_inv: 66.70% missing\n",
      "comp3_rate_percent_diff: 90.46% missing\n",
      "comp4_rate: 93.80% missing\n",
      "comp4_inv: 93.07% missing\n",
      "comp4_rate_percent_diff: 97.36% missing\n",
      "comp5_rate: 55.18% missing\n",
      "comp5_inv: 52.40% missing\n",
      "comp5_rate_percent_diff: 83.04% missing\n",
      "comp6_rate: 95.16% missing\n",
      "comp6_inv: 94.74% missing\n",
      "comp6_rate_percent_diff: 98.06% missing\n",
      "comp7_rate: 93.64% missing\n",
      "comp7_inv: 92.81% missing\n",
      "comp7_rate_percent_diff: 97.21% missing\n",
      "comp8_rate: 61.34% missing\n",
      "comp8_inv: 59.92% missing\n",
      "comp8_rate_percent_diff: 87.60% missing\n",
      "click_bool: 0.00% missing\n",
      "gross_bookings_usd: 97.21% missing\n",
      "booking_bool: 0.00% missing\n"
     ]
    }
   ],
   "source": [
    "# For each column, print the percentage of missing values\n",
    "for column in train_df.columns:\n",
    "    missing = train_df[column].isnull().sum()\n",
    "    percentage_missing = missing / num_records * 100\n",
    "    print(f'{column}: {percentage_missing:.2f}% missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a visitor has a history of purchasing hotels (value for visitor_hist_starrating, visitor_hist_adr_usd) - it might be advantageous to higher weight their behaviour in our model. Because they are more likely to completely go through the booking process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential drop candidates**\n",
    "- srch_query_affinity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64\n"
     ]
    }
   ],
   "source": [
    "# print the datatype of the 4th column\n",
    "train_df = train_df.convert_dtypes()\n",
    "print(train_df.dtypes['srch_saturday_night_bool'])\n",
    "\n",
    "\n",
    "train_df.astype({'srch_saturday_night_bool': 'bool'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dtype '<class 'pandas._libs.tslibs.timestamps.Timestamp'>' not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# turn correct_dtypes into a dictionary with the train_df column names as keys\u001b[39;00m\n\u001b[1;32m      6\u001b[0m correct_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(train_df\u001b[38;5;241m.\u001b[39mcolumns, correct_dtypes))\n\u001b[0;32m----> 7\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrect_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m train_df\u001b[38;5;241m.\u001b[39mdtypes\n",
      "File \u001b[0;32m~/Edu/UvA/Semester2/DMT/DMT-Group17/venv/lib/python3.11/site-packages/pandas/core/generic.py:6617\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6616\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6617\u001b[0m         res_col \u001b[38;5;241m=\u001b[39m \u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6618\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m   6619\u001b[0m         ex\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6620\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Error while type casting for column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   6621\u001b[0m         )\n",
      "File \u001b[0;32m~/Edu/UvA/Semester2/DMT/DMT-Group17/venv/lib/python3.11/site-packages/pandas/core/generic.py:6640\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6634\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6635\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6636\u001b[0m     ]\n\u001b[1;32m   6638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6639\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6640\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6641\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Edu/UvA/Semester2/DMT/DMT-Group17/venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Edu/UvA/Semester2/DMT/DMT-Group17/venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Edu/UvA/Semester2/DMT/DMT-Group17/venv/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Edu/UvA/Semester2/DMT/DMT-Group17/venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:231\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    225\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got the class instead. Try instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 231\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, NumpyEADtype):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# Ensure we don't end up with a NumpyExtensionArray\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n",
      "File \u001b[0;32m~/Edu/UvA/Semester2/DMT/DMT-Group17/venv/lib/python3.11/site-packages/pandas/core/dtypes/common.py:1666\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m npdtype\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m npdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m npdtype\n",
      "\u001b[0;31mTypeError\u001b[0m: dtype '<class 'pandas._libs.tslibs.timestamps.Timestamp'>' not understood"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "correct_dtypes = [int, pd.Timestamp, int, int, float, float, int, int, int, float, int, float, float, float, int, float, int, float, int, int, int, int, int, int, bool, float, float, bool, int, int, float, int, int, float, int, int, float, int, int, float, int, int, float, int, int, float, int, int, float, int, int, float]\n",
    "\n",
    "# turn correct_dtypes into a dictionary with the train_df column names as keys\n",
    "correct_dtypes = dict(zip(train_df.columns, correct_dtypes))\n",
    "train_df = train_df.astype(correct_dtypes)\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
